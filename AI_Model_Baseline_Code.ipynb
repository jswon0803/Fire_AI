{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a06cb40",
   "metadata": {},
   "source": [
    "# 0.데이터셋 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a781076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# 파일이 저장된 디렉토리 경로\n",
    "directory_path = './001.Training_data'\n",
    "\n",
    "# 디렉토리 내의 파일 리스트를 가져옵니다.\n",
    "filelist = os.listdir(directory_path)\n",
    "\n",
    "# 파일 리스트에서 CSV 파일만 필터링합니다.\n",
    "csv_files = [file for file in filelist if file.endswith('.csv')]\n",
    "\n",
    "# 각 CSV 파일을 읽어와 데이터프레임으로 정의합니다.\n",
    "# 데이터프레임을 저장할 리스트\n",
    "dataframes = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[:,:-9]\n",
    "    # '공장요율코드' 열 값이 'S'인 경우를 0으로, null인 경우를 7으로 변경하고 데이터 타입을 int로 변환\n",
    "    #df['화재안전등급(우량적용전)'].replace({'S': 0, '미평가': 7,'비특건': 7}, inplace=True)\n",
    "    #df['화재안전등급(우량적용전)'] = df['화재안전등급(우량적용전)'].astype(int)\n",
    "   \n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a79070",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.concat([dataframes[0], dataframes[1], dataframes[2], dataframes[3],dataframes[4]],axis=0)\n",
    "\n",
    "# 0번 컬럼 값을 1과 0으로 변경합니다.\n",
    "merge_df['사고여부'] = merge_df['사고여부'].map({'미사고': 0, '사고': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3b8dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_29108\\1017726561.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(-9999, inplace=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_29108\\1017726561.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('-9999', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 결측치를 -9999로 대체하는 함수 정의\n",
    "def replace_missing(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        elif df[col].dtype == object:\n",
    "            df[col].fillna('-9999', inplace=True)\n",
    "        elif np.issubdtype(df[col].dtype, np.number) and np.isinf(df[col]).any():\n",
    "            df[col].replace([np.inf, -np.inf], -9999, inplace=True)\n",
    "\n",
    "# 함수 호출로 결측치 대체\n",
    "replace_missing(merge_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1744b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0번 컬럼 값을 1과 0으로 변경합니다.\n",
    "merge_df['사고여부'] = merge_df['사고여부'].map({1: '사고', 0: '미사고'})\n",
    "\n",
    "# 나머지 object 타입 열을 더미 데이터로 변환합니다.\n",
    "object_cols = [col for col in merge_df.columns if merge_df[col].dtype == 'object' and col != '사고여부']\n",
    "merge_df = pd.get_dummies(merge_df, columns=object_cols, drop_first=True)\n",
    "\n",
    "# 수치형 변수를 추출합니다.\n",
    "numerical_cols = merge_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# 0번 컬럼을 제외한 나머지 데이터에 대해서 정규화를 수행합니다.\n",
    "scaler = StandardScaler()\n",
    "merge_df[numerical_cols] = scaler.fit_transform(merge_df[numerical_cols])\n",
    "\n",
    "\n",
    "# '사고여부'가 1인 클래스를 언더샘플링하려면:\n",
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(merge_df.drop('사고여부', axis=1), merge_df['사고여부'])\n",
    "\n",
    "# X_resampled와 y_resampled는 언더샘플링 된 데이터입니다.\n",
    "# 이제 이 데이터를 사용하여 작업할 수 있습니다.\n",
    "\n",
    "y_resampled = y_resampled.apply(lambda x: 1 if x == '사고' else 0)\n",
    "\n",
    "# 언더샘플링 후 데이터를 훈련 세트 (80%)와 테스트 세트 (20%)로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6209f93",
   "metadata": {},
   "source": [
    "# 0. 예측데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bdfafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = dataframes[-1]\n",
    "\n",
    "# 0번 컬럼 값을 1과 0으로 변경합니다.\n",
    "#df5['사고여부'] = df5['사고여부'].map({1: '사고', 0: '미사고'})\n",
    "\n",
    "# 나머지 object 타입 열을 더미 데이터로 변환합니다.\n",
    "object_cols = [col for col in df5.columns if df5[col].dtype == 'object' and col != '사고여부']\n",
    "df5 = pd.get_dummies(df5, columns=object_cols, drop_first=True)\n",
    "\n",
    "# 함수 호출로 결측치 대체\n",
    "replace_missing(df5)\n",
    "\n",
    "\n",
    "# 수치형 변수를 추출합니다.\n",
    "numerical_cols = df5.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# 0번 컬럼을 제외한 나머지 데이터에 대해서 정규화를 수행합니다.\n",
    "scaler = StandardScaler()\n",
    "df5[numerical_cols] = scaler.fit_transform(df5[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8390ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 열 추가 및 False로 초기화\n",
    "new_columns = ['용도명_가설건축물', '용도명_생활편익시설', '용도지역명2_유통상업지역', '토지이동상황_발전소', '토지이동상황_주.상복합용', '지형형상_삼각형', '지형형상_역삼각형']\n",
    "\n",
    "for column in new_columns:\n",
    "    df5[column] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86669814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['사고여부'] = df5['사고여부'].apply(lambda x: 0 if x == '미사고' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7538d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1의 컬럼 순서대로 df5의 컬럼을 재배치\n",
    "df5_reordered = df5[merge_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876e730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_X_train = df5_reordered.iloc[:, 1:]\n",
    "df5_y_result = df5_reordered.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429e29d",
   "metadata": {},
   "source": [
    " ## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0212a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 13.367110967636108초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import io  # Import the 'io' module instead of 'sklearn.externals.six'\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Decision Tree Model\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "min_cp = 0.01 #min(DT.cost_complexity_pruning_path(X_train, y_train).ccp_alphas)\n",
    "DT_model = DecisionTreeClassifier(ccp_alpha=min_cp)\n",
    "DT_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Decision Tree Evaluation\n",
    "real_sim_DT = DT_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "DT_cmtx = confusion_matrix(y_test, real_sim_DT)\n",
    "accuracy = accuracy_score(y_test, real_sim_DT)\n",
    "precision = precision_score(y_test, real_sim_DT)\n",
    "recall = recall_score(y_test, real_sim_DT)\n",
    "f1 = f1_score(y_test, real_sim_DT)\n",
    "\n",
    "df5_predict = DT_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_DT.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['DT']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(DT_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame(DT_model.feature_importances_, index=X_train.columns, columns=['Importance']).to_excel(writer, sheet_name='Feature Importance')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_DT}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "    \n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['DT'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_DT.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'DT_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_DT.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8da733",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c51345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 47.092134952545166초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Random Forest Model\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Evaluation\n",
    "real_sim_RF = RF.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "RF_cmtx = confusion_matrix(y_test, real_sim_RF)\n",
    "accuracy = accuracy_score(y_test, real_sim_RF)\n",
    "precision = precision_score(y_test, real_sim_RF)\n",
    "recall = recall_score(y_test, real_sim_RF)\n",
    "f1 = f1_score(y_test, real_sim_RF)\n",
    "\n",
    "df5_predict = RF.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_RF.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['RF']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(RF_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame(RF.feature_importances_, index=X_train.columns, columns=['Importance']).to_excel(writer, sheet_name='Feature Importance',)\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_RF}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['RF'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_RF.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'RF_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_RF.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed7396",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11d3b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 2.054497241973877초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB  # Changed from GaussianNB to BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Bayesian Model (Bernoulli Naive Bayes)\n",
    "BNB = BernoulliNB()  # Changed to BernoulliNB\n",
    "BNB.fit(X_train, y_train)\n",
    "\n",
    "# Bayesian Model Evaluation\n",
    "real_sim_BNB = BNB.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "BNB_cmtx = confusion_matrix(y_test, real_sim_BNB)\n",
    "accuracy = accuracy_score(y_test, real_sim_BNB)\n",
    "precision = precision_score(y_test, real_sim_BNB)\n",
    "recall = recall_score(y_test, real_sim_BNB)\n",
    "f1 = f1_score(y_test, real_sim_BNB)\n",
    "\n",
    "\n",
    "\n",
    "df5_predict = BNB.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_BNB.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['NB']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(BNB_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    # Feature importance is not applicable for Bernoulli Naive Bayes\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_BNB}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['NB'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_NB.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'NB_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_NB.csv\", mode='a', header=True, index=False)\n",
    "    \n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc344a4",
   "metadata": {},
   "source": [
    "## 4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da5f83a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 27.00323510169983초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "#KNN은 numpy형태로 x_train을 만들어야합니다. 따라서 해당코드실행뒤 다른 모델을 train하기위해선 다시  데이터프레임형태로 만들어야합니다.\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "# 위코드를 실행뒤 다른 코드를 진행하셔야합니다!\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.ascontiguousarray(X_resampled), y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN Model\n",
    "k_value = 5  # You can choose the appropriate k value\n",
    "KNN = KNeighborsClassifier(n_neighbors=k_value)\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "# KNN Model Evaluation\n",
    "real_sim_KNN = KNN.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "KNN_cmtx = confusion_matrix(y_test, real_sim_KNN)\n",
    "accuracy = accuracy_score(y_test, real_sim_KNN)\n",
    "precision = precision_score(y_test, real_sim_KNN)\n",
    "recall = recall_score(y_test, real_sim_KNN)\n",
    "f1 = f1_score(y_test, real_sim_KNN)\n",
    "\n",
    "\n",
    "df5_predict = KNN.predict((np.ascontiguousarray(df5_X_train)))\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_KNN.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['KNN']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(KNN_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_KNN}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "    \n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['KNN'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_KNN.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'KNN_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_KNN.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63026260",
   "metadata": {},
   "source": [
    "## 5. SVM (kernel = radial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d165845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차\n",
      "코드 실행 시간: 6703.564543247223초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assume X_resampled and y_resampled are your feature and target columns\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# RBF SVM Model\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "rbf_SVM.fit(X_train, y_train)\n",
    "\n",
    "# RBF SVM Model Evaluation\n",
    "real_sim_rbf_SVM = rbf_SVM.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "rbf_SVM_cmtx = confusion_matrix(y_test, real_sim_rbf_SVM)\n",
    "accuracy = accuracy_score(y_test, real_sim_rbf_SVM)\n",
    "precision = precision_score(y_test, real_sim_rbf_SVM)\n",
    "recall = recall_score(y_test, real_sim_rbf_SVM)\n",
    "f1 = f1_score(y_test, real_sim_rbf_SVM)\n",
    "\n",
    "print('1차')\n",
    "\n",
    "df5_predict = rbf_SVM.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_rbf_SVM.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['RBF SVM']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(rbf_SVM_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_rbf_SVM}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['RBF SVM'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_RBF_SVM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'RBF_SVM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_RBF_SVM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "    \n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b92a47",
   "metadata": {},
   "source": [
    "## 6. SVM (kernel = poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b8f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차\n",
      "코드 실행 시간: 4641.346827745438초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Polynomial SVM Model\n",
    "poly_SVM = SVC(kernel='poly', degree=3)  # You can adjust the degree parameter\n",
    "poly_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Polynomial SVM Model Evaluation\n",
    "real_sim_poly_SVM = poly_SVM.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "poly_SVM_cmtx = confusion_matrix(y_test, real_sim_poly_SVM)\n",
    "accuracy = accuracy_score(y_test, real_sim_poly_SVM)\n",
    "precision = precision_score(y_test, real_sim_poly_SVM)\n",
    "recall = recall_score(y_test, real_sim_poly_SVM)\n",
    "f1 = f1_score(y_test, real_sim_poly_SVM)\n",
    "\n",
    "print('1차')\n",
    "\n",
    "df5_predict = poly_SVM.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_poly_SVM.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['Polynomial SVM']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(poly_SVM_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_poly_SVM}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['Polynomial SVM'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_Polynomial_SVM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'Polynomial_SVM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_Polynomial_SVM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f71a2a",
   "metadata": {},
   "source": [
    "## 7. SVM (kernel = sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e0a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차\n",
      "코드 실행 시간: 4034.275359392166초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Sigmoid SVM Model\n",
    "sigmoid_SVM = SVC(kernel='sigmoid')\n",
    "sigmoid_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Sigmoid SVM Model Evaluation\n",
    "real_sim_sigmoid_SVM = sigmoid_SVM.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "sigmoid_SVM_cmtx = confusion_matrix(y_test, real_sim_sigmoid_SVM)\n",
    "accuracy = accuracy_score(y_test, real_sim_sigmoid_SVM)\n",
    "precision = precision_score(y_test, real_sim_sigmoid_SVM)\n",
    "recall = recall_score(y_test, real_sim_sigmoid_SVM)\n",
    "f1 = f1_score(y_test, real_sim_sigmoid_SVM)\n",
    "\n",
    "print('1차')\n",
    "\n",
    "df5_predict = sigmoid_SVM.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_sigmoid_SVM.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['Sigmoid SVM']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(sigmoid_SVM_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_sigmoid_SVM}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['Sigmoid SVM'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_Sigmoid_SVM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'Sigmoid_SVM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_Sigmoid_SVM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b85162c",
   "metadata": {},
   "source": [
    "## 8. SVM (kernel = linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eac3bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행중\n",
      "1차\n",
      "2차\n",
      "코드 실행 시간: 19352.82927632332초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Linear SVM Model\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "linear_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Linear SVM Model Evaluation\n",
    "real_sim_linear_SVM = linear_SVM.predict(X_test)\n",
    "\n",
    "print('진행중')\n",
    "# Confusion Matrix\n",
    "linear_SVM_cmtx = confusion_matrix(y_test, real_sim_linear_SVM)\n",
    "accuracy = accuracy_score(y_test, real_sim_linear_SVM)\n",
    "precision = precision_score(y_test, real_sim_linear_SVM)\n",
    "recall = recall_score(y_test, real_sim_linear_SVM)\n",
    "f1 = f1_score(y_test, real_sim_linear_SVM)\n",
    "\n",
    "print('1차')\n",
    "\n",
    "df5_predict = linear_SVM.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "print('2차')\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_linear_SVM.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['Linear SVM']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(linear_SVM_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_linear_SVM}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['Linear SVM'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_Linear_SVM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'Linear_SVM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_Linear_SVM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868aacbf",
   "metadata": {},
   "source": [
    "## 9. BA(BaggingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55a2910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 51.73133969306946초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Bagging Classifier (Random Forest)\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Bagging Model Evaluation\n",
    "real_sim_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "bagging_cmtx = confusion_matrix(y_test, real_sim_bagging)\n",
    "accuracy = accuracy_score(y_test, real_sim_bagging)\n",
    "precision = precision_score(y_test, real_sim_bagging)\n",
    "recall = recall_score(y_test, real_sim_bagging)\n",
    "f1 = f1_score(y_test, real_sim_bagging)\n",
    "\n",
    "df5_predict = bagging_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_bagging.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['BA']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(bagging_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_bagging}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['BA'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_BA.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'BA_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_BA.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d078b",
   "metadata": {},
   "source": [
    "## 10. Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1d3c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 9.393779754638672초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# AdaBoost Classifier\n",
    "base_estimator = DecisionTreeClassifier()  # You can customize the base estimator\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# AdaBoost Model Evaluation\n",
    "real_sim_adaboost = adaboost_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, real_sim_adaboost)\n",
    "precision = precision_score(y_test, real_sim_adaboost)\n",
    "recall = recall_score(y_test, real_sim_adaboost)\n",
    "f1 = f1_score(y_test, real_sim_adaboost)\n",
    "\n",
    "# Access feature importances of the first base estimator after fitting\n",
    "first_base_estimator = adaboost_model.estimators_[0]  \n",
    "feature_importance = first_base_estimator.feature_importances_\n",
    "feature_names = df5_X_train.columns\n",
    "\n",
    "df5_predict = adaboost_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_adaboost.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['AdaBoost']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance}).to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "    pd.DataFrame(confusion_matrix(y_test, real_sim_adaboost), index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_adaboost}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['AdaBoost'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_ADA.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'ADA_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_ADA.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559bcdf",
   "metadata": {},
   "source": [
    "## 11. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dba7cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.6034261\ttotal: 39.2ms\tremaining: 3.88s\n",
      "1:\tlearn: 0.5789369\ttotal: 48.6ms\tremaining: 2.38s\n",
      "2:\tlearn: 0.5675968\ttotal: 57.6ms\tremaining: 1.86s\n",
      "3:\tlearn: 0.5626883\ttotal: 66.5ms\tremaining: 1.6s\n",
      "4:\tlearn: 0.5586803\ttotal: 75.1ms\tremaining: 1.43s\n",
      "5:\tlearn: 0.5568280\ttotal: 83.8ms\tremaining: 1.31s\n",
      "6:\tlearn: 0.5555177\ttotal: 93ms\tremaining: 1.24s\n",
      "7:\tlearn: 0.5526775\ttotal: 101ms\tremaining: 1.17s\n",
      "8:\tlearn: 0.5497972\ttotal: 111ms\tremaining: 1.12s\n",
      "9:\tlearn: 0.5482031\ttotal: 119ms\tremaining: 1.07s\n",
      "10:\tlearn: 0.5467990\ttotal: 128ms\tremaining: 1.03s\n",
      "11:\tlearn: 0.5455212\ttotal: 137ms\tremaining: 1s\n",
      "12:\tlearn: 0.5437371\ttotal: 146ms\tremaining: 975ms\n",
      "13:\tlearn: 0.5422803\ttotal: 155ms\tremaining: 951ms\n",
      "14:\tlearn: 0.5409861\ttotal: 163ms\tremaining: 925ms\n",
      "15:\tlearn: 0.5402020\ttotal: 172ms\tremaining: 902ms\n",
      "16:\tlearn: 0.5395935\ttotal: 180ms\tremaining: 880ms\n",
      "17:\tlearn: 0.5382052\ttotal: 189ms\tremaining: 860ms\n",
      "18:\tlearn: 0.5360392\ttotal: 198ms\tremaining: 843ms\n",
      "19:\tlearn: 0.5346877\ttotal: 207ms\tremaining: 827ms\n",
      "20:\tlearn: 0.5312157\ttotal: 216ms\tremaining: 812ms\n",
      "21:\tlearn: 0.5299712\ttotal: 225ms\tremaining: 798ms\n",
      "22:\tlearn: 0.5288909\ttotal: 234ms\tremaining: 784ms\n",
      "23:\tlearn: 0.5279240\ttotal: 243ms\tremaining: 769ms\n",
      "24:\tlearn: 0.5261003\ttotal: 252ms\tremaining: 755ms\n",
      "25:\tlearn: 0.5250168\ttotal: 260ms\tremaining: 741ms\n",
      "26:\tlearn: 0.5236293\ttotal: 269ms\tremaining: 728ms\n",
      "27:\tlearn: 0.5215938\ttotal: 278ms\tremaining: 715ms\n",
      "28:\tlearn: 0.5204084\ttotal: 287ms\tremaining: 702ms\n",
      "29:\tlearn: 0.5190118\ttotal: 296ms\tremaining: 690ms\n",
      "30:\tlearn: 0.5183732\ttotal: 304ms\tremaining: 677ms\n",
      "31:\tlearn: 0.5175621\ttotal: 313ms\tremaining: 665ms\n",
      "32:\tlearn: 0.5165997\ttotal: 322ms\tremaining: 653ms\n",
      "33:\tlearn: 0.5148113\ttotal: 330ms\tremaining: 642ms\n",
      "34:\tlearn: 0.5136300\ttotal: 339ms\tremaining: 630ms\n",
      "35:\tlearn: 0.5125017\ttotal: 348ms\tremaining: 618ms\n",
      "36:\tlearn: 0.5111171\ttotal: 357ms\tremaining: 607ms\n",
      "37:\tlearn: 0.5100038\ttotal: 366ms\tremaining: 597ms\n",
      "38:\tlearn: 0.5086530\ttotal: 375ms\tremaining: 586ms\n",
      "39:\tlearn: 0.5076984\ttotal: 383ms\tremaining: 575ms\n",
      "40:\tlearn: 0.5070036\ttotal: 391ms\tremaining: 563ms\n",
      "41:\tlearn: 0.5059789\ttotal: 401ms\tremaining: 553ms\n",
      "42:\tlearn: 0.5052655\ttotal: 410ms\tremaining: 543ms\n",
      "43:\tlearn: 0.5042684\ttotal: 418ms\tremaining: 532ms\n",
      "44:\tlearn: 0.5037255\ttotal: 427ms\tremaining: 522ms\n",
      "45:\tlearn: 0.5019635\ttotal: 436ms\tremaining: 512ms\n",
      "46:\tlearn: 0.5010862\ttotal: 445ms\tremaining: 502ms\n",
      "47:\tlearn: 0.4999945\ttotal: 454ms\tremaining: 492ms\n",
      "48:\tlearn: 0.4987018\ttotal: 463ms\tremaining: 482ms\n",
      "49:\tlearn: 0.4977137\ttotal: 472ms\tremaining: 472ms\n",
      "50:\tlearn: 0.4968423\ttotal: 480ms\tremaining: 461ms\n",
      "51:\tlearn: 0.4961822\ttotal: 489ms\tremaining: 451ms\n",
      "52:\tlearn: 0.4957025\ttotal: 498ms\tremaining: 441ms\n",
      "53:\tlearn: 0.4950084\ttotal: 506ms\tremaining: 431ms\n",
      "54:\tlearn: 0.4942575\ttotal: 515ms\tremaining: 421ms\n",
      "55:\tlearn: 0.4933009\ttotal: 523ms\tremaining: 411ms\n",
      "56:\tlearn: 0.4928423\ttotal: 532ms\tremaining: 401ms\n",
      "57:\tlearn: 0.4918168\ttotal: 541ms\tremaining: 392ms\n",
      "58:\tlearn: 0.4910835\ttotal: 550ms\tremaining: 382ms\n",
      "59:\tlearn: 0.4903167\ttotal: 559ms\tremaining: 372ms\n",
      "60:\tlearn: 0.4892311\ttotal: 568ms\tremaining: 363ms\n",
      "61:\tlearn: 0.4886977\ttotal: 576ms\tremaining: 353ms\n",
      "62:\tlearn: 0.4878433\ttotal: 584ms\tremaining: 343ms\n",
      "63:\tlearn: 0.4867262\ttotal: 593ms\tremaining: 334ms\n",
      "64:\tlearn: 0.4860280\ttotal: 602ms\tremaining: 324ms\n",
      "65:\tlearn: 0.4852861\ttotal: 611ms\tremaining: 315ms\n",
      "66:\tlearn: 0.4845348\ttotal: 620ms\tremaining: 305ms\n",
      "67:\tlearn: 0.4829371\ttotal: 629ms\tremaining: 296ms\n",
      "68:\tlearn: 0.4817125\ttotal: 638ms\tremaining: 286ms\n",
      "69:\tlearn: 0.4811022\ttotal: 647ms\tremaining: 277ms\n",
      "70:\tlearn: 0.4798683\ttotal: 656ms\tremaining: 268ms\n",
      "71:\tlearn: 0.4783387\ttotal: 665ms\tremaining: 259ms\n",
      "72:\tlearn: 0.4777341\ttotal: 674ms\tremaining: 249ms\n",
      "73:\tlearn: 0.4771423\ttotal: 682ms\tremaining: 240ms\n",
      "74:\tlearn: 0.4765453\ttotal: 691ms\tremaining: 230ms\n",
      "75:\tlearn: 0.4756599\ttotal: 700ms\tremaining: 221ms\n",
      "76:\tlearn: 0.4748278\ttotal: 709ms\tremaining: 212ms\n",
      "77:\tlearn: 0.4743826\ttotal: 717ms\tremaining: 202ms\n",
      "78:\tlearn: 0.4736643\ttotal: 725ms\tremaining: 193ms\n",
      "79:\tlearn: 0.4726883\ttotal: 734ms\tremaining: 184ms\n",
      "80:\tlearn: 0.4719685\ttotal: 743ms\tremaining: 174ms\n",
      "81:\tlearn: 0.4713054\ttotal: 752ms\tremaining: 165ms\n",
      "82:\tlearn: 0.4706229\ttotal: 760ms\tremaining: 156ms\n",
      "83:\tlearn: 0.4700916\ttotal: 769ms\tremaining: 146ms\n",
      "84:\tlearn: 0.4693514\ttotal: 778ms\tremaining: 137ms\n",
      "85:\tlearn: 0.4688268\ttotal: 786ms\tremaining: 128ms\n",
      "86:\tlearn: 0.4683829\ttotal: 795ms\tremaining: 119ms\n",
      "87:\tlearn: 0.4675385\ttotal: 804ms\tremaining: 110ms\n",
      "88:\tlearn: 0.4669781\ttotal: 813ms\tremaining: 100ms\n",
      "89:\tlearn: 0.4663844\ttotal: 821ms\tremaining: 91.3ms\n",
      "90:\tlearn: 0.4653730\ttotal: 830ms\tremaining: 82.1ms\n",
      "91:\tlearn: 0.4647480\ttotal: 839ms\tremaining: 72.9ms\n",
      "92:\tlearn: 0.4640854\ttotal: 848ms\tremaining: 63.9ms\n",
      "93:\tlearn: 0.4633772\ttotal: 857ms\tremaining: 54.7ms\n",
      "94:\tlearn: 0.4627179\ttotal: 866ms\tremaining: 45.6ms\n",
      "95:\tlearn: 0.4617077\ttotal: 875ms\tremaining: 36.4ms\n",
      "96:\tlearn: 0.4612118\ttotal: 883ms\tremaining: 27.3ms\n",
      "97:\tlearn: 0.4604225\ttotal: 892ms\tremaining: 18.2ms\n",
      "98:\tlearn: 0.4591590\ttotal: 900ms\tremaining: 9.09ms\n",
      "99:\tlearn: 0.4585108\ttotal: 909ms\tremaining: 0us\n",
      "코드 실행 시간: 12.357779502868652초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# CatBoost Classifier\n",
    "catboost_model = CatBoostClassifier(iterations=100, random_state=42)\n",
    "catboost_model.fit(X_train, y_train, cat_features=[])\n",
    "\n",
    "# CatBoost Model Evaluation\n",
    "real_sim_catboost = catboost_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "catboost_cmtx = confusion_matrix(y_test, real_sim_catboost)\n",
    "accuracy = accuracy_score(y_test, real_sim_catboost)\n",
    "precision = precision_score(y_test, real_sim_catboost)\n",
    "recall = recall_score(y_test, real_sim_catboost)\n",
    "f1 = f1_score(y_test, real_sim_catboost)\n",
    "\n",
    "\n",
    "df5_predict = catboost_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_catboost.xlsx\") as writer:\n",
    "    pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['CatBoost']).to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "    pd.DataFrame(catboost_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "  \n",
    "    # Save Feature Importance\n",
    "    feature_importance_df = pd.DataFrame({'Feature': df5_X_train.columns, 'Importance': catboost_model.feature_importances_})\n",
    "    feature_importance_df.to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_catboost}).to_excel(writer, sheet_name='Test Data Predict')\n",
    "    \n",
    "    \n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['CatBoost'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_CAT.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'CAT_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_CAT.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94dadba",
   "metadata": {},
   "source": [
    "## 12. Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db135174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 3.4840102195739746초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost Model Evaluation\n",
    "real_sim_xgboost = xgboost_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "xgboost_cmtx = confusion_matrix(y_test, real_sim_xgboost)\n",
    "accuracy = accuracy_score(y_test, real_sim_xgboost)\n",
    "precision = precision_score(y_test, real_sim_xgboost)\n",
    "recall = recall_score(y_test, real_sim_xgboost)\n",
    "f1 = f1_score(y_test, real_sim_xgboost)\n",
    "\n",
    "\n",
    "\n",
    "df5_predict = xgboost_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_xgboost.xlsx\") as writer:\n",
    "    # Save Summary\n",
    "    summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['XGBoost'])\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    pd.DataFrame(xgboost_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "    # Save Feature Importance\n",
    "    feature_importance_df = pd.DataFrame({'Feature': df5_X_train.columns, 'Importance': xgboost_model.feature_importances_})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    feature_importance_df.to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "\n",
    "    # Save Test Data Predictions\n",
    "    test_data_df = pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_xgboost})\n",
    "    test_data_df.to_excel(writer, sheet_name='Test Data Predict', index=False)\n",
    "\n",
    "        \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['XGBoost'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_XG.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'XG_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_XG.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacc322",
   "metadata": {},
   "source": [
    "## 13. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7df5d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 실행 시간: 141.32453894615173초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "# GBM Classifier\n",
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# GBM Model Evaluation\n",
    "real_sim_gbm = gbm_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "gbm_cmtx = confusion_matrix(y_test, real_sim_gbm)\n",
    "accuracy = accuracy_score(y_test, real_sim_gbm)\n",
    "precision = precision_score(y_test, real_sim_gbm)\n",
    "recall = recall_score(y_test, real_sim_gbm)\n",
    "f1 = f1_score(y_test, real_sim_gbm)\n",
    "\n",
    "\n",
    "df5_predict = gbm_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_gbm.xlsx\") as writer:\n",
    "    # Save Summary\n",
    "    summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['GBM'])\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    pd.DataFrame(gbm_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "    # Save Feature Importance\n",
    "    feature_importance_df = pd.DataFrame({'Feature': df5_X_train.columns, 'Importance': gbm_model.feature_importances_})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    feature_importance_df.to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "\n",
    "    # Save Test Data Predictions\n",
    "    test_data_df = pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_gbm})\n",
    "    test_data_df.to_excel(writer, sheet_name='Test Data Predict', index=False)\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['GBM'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_GBM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'GBM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_GBM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "    # 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d95ab",
   "metadata": {},
   "source": [
    "## 14. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8a86650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5761 - accuracy: 0.7098 - val_loss: 0.5565 - val_accuracy: 0.7236\n",
      "Epoch 2/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5493 - accuracy: 0.7274 - val_loss: 0.5415 - val_accuracy: 0.7295\n",
      "Epoch 3/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5370 - accuracy: 0.7337 - val_loss: 0.5366 - val_accuracy: 0.7343\n",
      "Epoch 4/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5279 - accuracy: 0.7387 - val_loss: 0.5283 - val_accuracy: 0.7376\n",
      "Epoch 5/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5196 - accuracy: 0.7439 - val_loss: 0.5242 - val_accuracy: 0.7427\n",
      "Epoch 6/10\n",
      "3769/3769 [==============================] - 12s 3ms/step - loss: 0.5136 - accuracy: 0.7480 - val_loss: 0.5205 - val_accuracy: 0.7429\n",
      "Epoch 7/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5077 - accuracy: 0.7506 - val_loss: 0.5178 - val_accuracy: 0.7445\n",
      "Epoch 8/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.5019 - accuracy: 0.7541 - val_loss: 0.5194 - val_accuracy: 0.7471\n",
      "Epoch 9/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.4971 - accuracy: 0.7563 - val_loss: 0.5147 - val_accuracy: 0.7470\n",
      "Epoch 10/10\n",
      "3769/3769 [==============================] - 13s 3ms/step - loss: 0.4931 - accuracy: 0.7589 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "1178/1178 [==============================] - 1s 622us/step\n",
      "5060/5060 [==============================] - 4s 707us/step\n",
      "코드 실행 시간: 135.33740639686584초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "df5_X_train_scaled = scaler.transform(df5_X_train)  # 추가: df5_X_train도 스케일링\n",
    "\n",
    "# DNN Model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# DNN Model Evaluation\n",
    "real_sim_dnn = (model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "dnn_cmtx = confusion_matrix(y_test, real_sim_dnn)\n",
    "accuracy = accuracy_score(y_test, real_sim_dnn)\n",
    "precision = precision_score(y_test, real_sim_dnn)\n",
    "recall = recall_score(y_test, real_sim_dnn)\n",
    "f1 = f1_score(y_test, real_sim_dnn)\n",
    "\n",
    "# df5 데이터 예측 및 평가\n",
    "df5_predict_prob = model.predict(df5_X_train_scaled)\n",
    "df5_predict = (df5_predict_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_ann.xlsx\") as writer:\n",
    "    # Save Summary\n",
    "    summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['ANN'])\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    pd.DataFrame(dnn_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "    # ... (other sheets if needed)\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['ANN'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_ANN.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'ANN_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_ANN.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "    \n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa6e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0f86647",
   "metadata": {},
   "source": [
    "## 14-1. DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc5eae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3769/3769 [==============================] - 15s 4ms/step - loss: 0.5735 - accuracy: 0.7108 - val_loss: 0.5640 - val_accuracy: 0.7206\n",
      "Epoch 2/10\n",
      "3769/3769 [==============================] - 15s 4ms/step - loss: 0.5451 - accuracy: 0.7304 - val_loss: 0.5377 - val_accuracy: 0.7348\n",
      "Epoch 3/10\n",
      "3769/3769 [==============================] - 15s 4ms/step - loss: 0.5298 - accuracy: 0.7393 - val_loss: 0.5267 - val_accuracy: 0.7415\n",
      "Epoch 4/10\n",
      "3769/3769 [==============================] - 16s 4ms/step - loss: 0.5165 - accuracy: 0.7477 - val_loss: 0.5193 - val_accuracy: 0.7483\n",
      "Epoch 5/10\n",
      "3769/3769 [==============================] - 16s 4ms/step - loss: 0.5067 - accuracy: 0.7536 - val_loss: 0.5168 - val_accuracy: 0.7497\n",
      "Epoch 6/10\n",
      "3769/3769 [==============================] - 15s 4ms/step - loss: 0.4965 - accuracy: 0.7601 - val_loss: 0.5126 - val_accuracy: 0.7546\n",
      "Epoch 7/10\n",
      "3769/3769 [==============================] - 16s 4ms/step - loss: 0.4884 - accuracy: 0.7647 - val_loss: 0.5038 - val_accuracy: 0.7585\n",
      "Epoch 8/10\n",
      "3769/3769 [==============================] - 15s 4ms/step - loss: 0.4812 - accuracy: 0.7690 - val_loss: 0.5003 - val_accuracy: 0.7592\n",
      "Epoch 9/10\n",
      "3769/3769 [==============================] - 16s 4ms/step - loss: 0.4721 - accuracy: 0.7737 - val_loss: 0.4954 - val_accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "3769/3769 [==============================] - 17s 5ms/step - loss: 0.4650 - accuracy: 0.7771 - val_loss: 0.4920 - val_accuracy: 0.7665\n",
      "1178/1178 [==============================] - 1s 1ms/step\n",
      "5060/5060 [==============================] - 6s 1ms/step\n",
      "코드 실행 시간: 166.20848631858826초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "df5_X_train_scaled = scaler.transform(df5_X_train)  # 추가: df5_X_train도 스케일링\n",
    "\n",
    "# DNN Model (Deeper Neural Network)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(128, activation='relu'))  # Additional hidden layer\n",
    "model.add(Dense(64, activation='relu'))   # Additional hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# DNN Model Evaluation\n",
    "real_sim_dnn = (model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "dnn_cmtx = confusion_matrix(y_test, real_sim_dnn)\n",
    "accuracy = accuracy_score(y_test, real_sim_dnn)\n",
    "precision = precision_score(y_test, real_sim_dnn)\n",
    "recall = recall_score(y_test, real_sim_dnn)\n",
    "f1 = f1_score(y_test, real_sim_dnn)\n",
    "\n",
    "# df5 데이터 예측 및 평가\n",
    "df5_predict_prob = model.predict(df5_X_train_scaled)\n",
    "df5_predict = (df5_predict_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_dnn.xlsx\") as writer:\n",
    "    # Save Summary\n",
    "    summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['DNN'])\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    pd.DataFrame(dnn_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "    # ... (other sheets if needed)\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['DNN'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_DNN.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'DNN_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_DNN.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "    \n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d12074",
   "metadata": {},
   "source": [
    "## 15. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b705c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programming\\miniconda\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1885/1885 [==============================] - 13s 7ms/step - loss: 0.5721 - accuracy: 0.7100 - val_loss: 0.5519 - val_accuracy: 0.7256\n",
      "Epoch 2/7\n",
      "1885/1885 [==============================] - 12s 7ms/step - loss: 0.5446 - accuracy: 0.7310 - val_loss: 0.5399 - val_accuracy: 0.7315\n",
      "Epoch 3/7\n",
      "1885/1885 [==============================] - 12s 7ms/step - loss: 0.5300 - accuracy: 0.7388 - val_loss: 0.5310 - val_accuracy: 0.7383\n",
      "Epoch 4/7\n",
      "1885/1885 [==============================] - 12s 7ms/step - loss: 0.5183 - accuracy: 0.7437 - val_loss: 0.5269 - val_accuracy: 0.7395\n",
      "Epoch 5/7\n",
      "1885/1885 [==============================] - 12s 7ms/step - loss: 0.5080 - accuracy: 0.7503 - val_loss: 0.5215 - val_accuracy: 0.7439\n",
      "Epoch 6/7\n",
      "1885/1885 [==============================] - 12s 7ms/step - loss: 0.4986 - accuracy: 0.7553 - val_loss: 0.5194 - val_accuracy: 0.7452\n",
      "Epoch 7/7\n",
      "1885/1885 [==============================] - 12s 7ms/step - loss: 0.4910 - accuracy: 0.7605 - val_loss: 0.5153 - val_accuracy: 0.7509\n",
      "1178/1178 [==============================] - 2s 2ms/step\n",
      "5060/5060 [==============================] - 8s 2ms/step\n",
      "코드 실행 시간: 101.26267743110657초\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "df5_X_train_scaled = scaler.transform(df5_X_train)  # 추가: df5_X_train도 스케일링\n",
    "\n",
    "# Reshape data for LSTM (assuming X_train and X_test are 2D arrays)\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "df5_X_train_reshaped = df5_X_train_scaled.reshape((df5_X_train_scaled.shape[0], 1, df5_X_train_scaled.shape[1]))\n",
    "\n",
    "# LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=7, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# LSTM Model Evaluation\n",
    "real_sim_lstm = (model.predict(X_test_reshaped) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "lstm_cmtx = confusion_matrix(y_test, real_sim_lstm)\n",
    "accuracy = accuracy_score(y_test, real_sim_lstm)\n",
    "precision = precision_score(y_test, real_sim_lstm)\n",
    "recall = recall_score(y_test, real_sim_lstm)\n",
    "f1 = f1_score(y_test, real_sim_lstm)\n",
    "\n",
    "# df5 데이터 예측 및 평가\n",
    "df5_predict_prob = model.predict(df5_X_train_reshaped)\n",
    "df5_predict = (df5_predict_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"./result_summary_lstm.xlsx\") as writer:\n",
    "    # Save Summary\n",
    "    summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['LSTM'])\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    pd.DataFrame(lstm_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "    \n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['LSTM'])\n",
    "df5_results.to_csv(\"./11.result/score/final_result_LSTM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'LSTM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_LSTM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4904248",
   "metadata": {},
   "source": [
    "## 16. LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a654b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 75388, number of negative: 75341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5729\n",
      "[LightGBM] [Info] Number of data points in the train set: 150729, number of used features: 196\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500156 -> initscore=0.000624\n",
      "[LightGBM] [Info] Start training from score 0.000624\n",
      "코드 실행 시간: 2.5823004245758057초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 코드 실행 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# LightGBM Classifier\n",
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# LightGBM Model Evaluation\n",
    "real_sim_lgbm = lgbm_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "lgbm_cmtx = confusion_matrix(y_test, real_sim_lgbm)\n",
    "accuracy = accuracy_score(y_test, real_sim_lgbm)\n",
    "precision = precision_score(y_test, real_sim_lgbm)\n",
    "recall = recall_score(y_test, real_sim_lgbm)\n",
    "f1 = f1_score(y_test, real_sim_lgbm)\n",
    "\n",
    "df5_predict = lgbm_model.predict(df5_X_train)\n",
    "df5_accuracy = accuracy_score(df5_y_result, df5_predict)\n",
    "df5_precision = precision_score(df5_y_result, df5_predict)\n",
    "df5_recall = recall_score(df5_y_result, df5_predict)\n",
    "df5_f1 = f1_score(df5_y_result, df5_predict)\n",
    "\n",
    "# Save Results to Excel\n",
    "with pd.ExcelWriter(\"result_summary_lgbm.xlsx\") as writer:\n",
    "    # Save Summary\n",
    "    summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1]}, index=['LightGBM'])\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index_label='Model')\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    pd.DataFrame(lgbm_cmtx, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive']).to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "    # Save Feature Importance\n",
    "    feature_importance_df = pd.DataFrame({'Feature': df5_X_train.columns, 'Importance': lgbm_model.feature_importances_})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    feature_importance_df.to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "\n",
    "    # Save Test Data Predictions\n",
    "    test_data_df = pd.DataFrame({'Actual': y_test, 'Predicted': real_sim_lgbm})\n",
    "    test_data_df.to_excel(writer, sheet_name='Test Data Predict', index=False)\n",
    "\n",
    "df5_results = pd.DataFrame({'Accuracy': [df5_accuracy], 'Precision': [df5_precision], 'Recall': [df5_recall], 'F1 Score': [df5_f1]}, index=['LightGBM'])\n",
    "df5_results.to_csv(\"./11.result/score/score_result_LGBM.csv\", index_label='Model')\n",
    "\n",
    "df5_predictions = pd.DataFrame({'Actual': df5_y_result, 'LGBM_Predicted': df5_predict})\n",
    "df5_predictions.to_csv(\"./11.result/predict/final_result_LGBM.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# 코드 실행 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# 실행 시간 출력\n",
    "print(f\"코드 실행 시간: {execution_time}초\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[py310]",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
